# Модель Lenet: от обучения к развертыванию на устройстве

## 1 Предисловие

### 1.1 Целевая аудитория

Этот документ (руководство) предназначен в основном для следующих специалистов:
- Инженеры технической поддержки
- Инженеры разработки программного обеспечения
- Клиентов, работающих с AI приложениями

## 2 Введение в модель Lenet

Lenet - это название серии сетей, включающей Lenet1 - Lenet5, предложенной Yann LeCun и другими в 1990 году в статье "Handwritten Digit Recognition with a Back-Propagation Network", и является "Hello World" сверточных нейронных сетей. Здесь мы используем Lenet в качестве примера для объяснения полного процесса развертывания модели AI на платформе Tina - от обучения до работы на устройстве.

Детальный процесс включает обучение модели, импорт модели, квантизацию модели, взаимодействие модели, экспорт модели, моделирование модели, профилирование модели и развертывание модели на устройстве. Это показано на диаграмме ниже:

![image-20221207185412148](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207185412148.png)

<center>Рисунок 3-1: процесс развертывания NPU</center>

Далее начнём с начала.

### 2.1 Обучение модели

В этом примере используется фреймворк keras для написания и обучения сети lenet5. После завершения обучения модель экспортируется в формат h5. Acuity tools изначально поддерживает формат H5.

Структура модели:

![image-20221207185520650](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207185520650.png)

<center>Рисунок 3-2: структура модели lenet5</center>

После завершения обучения проверьте, соответствует ли точность требуемым целям обучения. В этом примере точность достигла 97%, что достаточно для развертывания:

![image-20221207185544323](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207185544323.png)

Сохраните выходную модель как lenet.h5,

![image-20221207185621907](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207185621907.png)

<center>Рисунок 3-4: файл модели lenet</center>

Используйте netron для просмотра структуры модели:

![image-20221207185721712](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207185721712.png)

<center>Рисунок 3-5: просмотр структуры модели lenet</center>

На данный момент нам удалось получить исходную модель, и мы можем приступить к развертыванию на ПК и на устройстве. Следующий этап - импорт модели.

### 2.2 Импорт модели

Перед выполнением операции импорта сначала посмотрите структуру директории развертывания:

Как показано ниже, директория data содержит изображения из набора данных mnist. Её функция - служить входными данными для квантизации после обучения, чтобы предоставить алгоритму квантизации справочную информацию о распределении входных данных в реальной сцене. Файл dataset.txt содержит ссылку на директорию data. Инструмент найдёт каждое изображение в директории data через файл dataset.txt.

![image-20221207185811861](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207185811861.png)

<center>Рисунок 3-6: структура директории развертывания</center>

Набор данных:

![image-2022120718588762](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-2022120718588762.png)

<center>Рисунок 3-7: набор данных изображений для квантизации</center>

### 2.3 Импорт модели

Используйте инструмент pegasus из acuity tool, предоставленный VeriSilicon, для импорта модели.

```
pegasus import onnx --model yolact-sim.onnx --output-model yolact-sim.json --output-data yolact-sim.data
```

Целью импорта модели является преобразование открытой модели в файл описания сетевой модели VIP (.json) и файл весов (.data)

![image-20221207185921978](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207185921978.png)

<center>Рисунок 3-8: импорт NPU</center>

Далее выполняется импорт модели lenet.h5.

```
pegasus import keras --model lenet.h5 --output-data lenet.data --output-model lenet.json
```

После успешного выполнения в директории появляются файлы lenet.json и lenet.data - соответственно файл структуры модели формата VeriSilicon и файл весов модели.

![image-20221207185955890](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207185955890.png)

<center>Рисунок 3-9: импорт модели</center>

На этапе импорта инструмент pegasus также выполняет анализ структуры модели и выводит результаты:

![image-20221207190015642](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207190015642.png)

<center>Рисунок 3-10: описание структуры модели</center>

Этап импорта ещё не завершен. Нам нужно создать файл описания входа и выхода сети. Это также требуется инструментом acuity tool. Описание входа и выхода - это текстовый файл в формате YML. Далее мы будем изменять файл YML для конфигурации параметров модели, формата входного/выходного тензора и другой информации.

#### 2.3.1 Создание YML файлов входа/выхода

YML файл описывает вход и выход сети, например форму входного изображения, коэффициенты нормализации (средние значения, нулевая точка), формат изображения, формат вывода тензора, способ постобработки и т.д. Команда:

```
pegasus generate inputmeta --model lenet.json --input-meta-output lenet-inputmeta.yml pegasus
generate postprocess-file --model lenet.json --postprocess-file-output lenet-postprocess-file.yml
```

После успешного выполнения команды в директории появляются два новых файла - YML файл входа и выхода.

![image-20221207190103043](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207190103043.png)

<center>Рисунок 3-11: создание YML файла</center>

На этом этап импорта модели полностью завершен. Начиная с этого момента, модель уже преобразована в файлы модели формата VeriSilicon. Следующие шаги менее связаны с исходной моделью.

Перед выполнением следующего этапа квантизации модели нам нужно изменить параметры scale и mean в файле input yml, чтобы они совпадали с параметрами при обучении.

Коэффициенты mean и scale в коде обучения:

![image-20221207190126855](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207190126855.png)

<center>Рисунок 3-12: среднее значение и масштаб в коде обучения</center>

На основе кода, mean = 0, scale = 1/255 = 0.0039.

Измените YML на соответствующие значения:

![image-20221207190147405](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207190147405.png)

<center>Рисунок 3-13: изменение параметра Scale входного YML</center>

### 2.4 Квантизация модели

Этот NPU поддерживает три типа квантизации: uint8, int8, int16. Исходя из баланса между скоростью взаимодействия и точностью, мы используем int8, асимметричный режим квантизации. Команда квантизации:

```
pegasus quantize --model lenet.json --model-data lenet.data --batch-size 1 --device CPU --withinput-meta lenet-inputmeta.yml --rebuild --model-quantize lenet.quantilize --quantizer asymmetric_affine --qtype uint8
```

После выполнения команды в директории проекта будет создан новый файл таблицы квантизации

![image-20221207190243780](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207190243780.png)

<center>Рисунок 2-14: файл таблицы квантизации</center>

### 2.5 Предварительное взаимодействие модели

```
pegasus inference --model lenet.json --model-data lenet.data --batch-size 1 --dtype quantized --model-quantize lenet.quantilize --device CPU --with-input-meta lenet-inputmeta.yml --postprocess-file lenet-postprocess-file.yml --iterations 10
```

В параметрах --batch-size 1 означает обработку 1 изображения при каждом взаимодействии. В нашем наборе данных содержится 10 изображений, поэтому необходимо запустить 10 раз для обработки всех. Это то, что делает параметр --iterations 10.

После успешного запуска в директории появляется 20 текстовых файлов .tensor. В файлах сохраняются входные и выходные данные тензора для каждого изображения. По умолчанию сохраняются только входной и выходной тензоры. Вы можете сохранить тензоры каждого уровня с помощью следующей команды:

```
pegasus dump --model lenet.json --model-data lenet.data --with-input-meta lenet-inputmeta.yml
```

Файлы тензора, созданные после завершения взаимодействия:

![image-20221207190401783](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221207190401783.png)

Мы можем видеть из вывода команды, верно ли выполнено взаимодействие. На примере первых шести результатов мы можем видеть, что максимальная вероятность в выводе top5 - это 0, 1, 2, 3, 4... соответственно, что совпадает с порядком данных изображений, введённых в файле dataset.txt.

![image-20221208090925317](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208090925317.png)

<center>Рисунок 2-16: вывод процесса взаимодействия развертывания</center>

Выходной тензор - это выход последнего слоя softmax, то есть вероятность для чисел 0-9. На примере выходного тензора 9-го изображения максимальная вероятность - 9, как показано ниже:

![image-20221208090956262](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208090956262.png)

<center>Рисунок 2-17: выход softmax</center>

Входным является нормализованные данные входного изображения в виде чисел с плавающей точкой:

![image-20221208091015981](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091015981.png)

<center>Рисунок 2-18: входной тензор</center>

На этом этап предварительного взаимодействия модели завершается. Переходим к следующему этапу - экспорту модели.

### 2.6 Экспорт кода и файла NBG

Команда экспорта кода показана ниже. Разница между двумя командами только в опциях --pack-nbg-unify и --pack-nbg-viplite, остальное идентично. --pack-nbg-unify создаёт код для стороны моделирования, в то время как --pack-nbg-viplite создаёт код для развертывания на устройстве. Обе команды выполняются отдельно.

```
pegasus export ovxlib --model lenet.json --model-data lenet.data --dtype quantized --model-quantize
lenet.quantilize --batch-size 1 --save-fused-graph --target-ide-project 'linux64' --with-inputmeta
lenet-inputmeta.yml --postprocess-file lenet-postprocess-file.yml --output-path ovxlib/lenet/
lenet --pack-nbg-unify --optimize "VIP9000PICO_PID0XEE" --viv-sdk ${VIV_SDK}
```

```
pegasus export ovxlib --model lenet.json --model-data lenet.data --dtype quantized --model-quantize
lenet.quantilize --batch-size 1 --save-fused-graph --target-ide-project 'linux64' --with-inputmeta
lenet-inputmeta.yml --postprocess-file lenet-postprocess-file.yml --output-path ovxlib/lenet/
lenet --pack-nbg-viplite --optimize "VIP9000PICO_PID0XEE" --viv-sdk ${VIV_SDK}
```

После завершения выполнения код проекта и файл NBG созданы:

![image-20221208091107463](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091107463.png)

<center>Рисунок 2-19: экспорт модели и кода проекта</center>

Экспортированный файл NBG можно использовать для запуска на NPU.

Проект ovxlib/lenet/ используется для моделирования и профилирования.

Проект ovxlib/lenet_nbg_viplite/ можно развернуть на устройстве.

ovxlib/lenet_nbg_unify и ovxlib/lenet_nbg_unify_ovx пока можно не рассматривать, они не используются.

Далее переходим к этапу моделирования модели.

### 2.7 Моделирование модели

Как упомянуто выше, ovxlib/lenet/ - это проект для моделирования и анализа профилирования. Ниже мы запустим IDE для моделирования.

#### 2.7.1 Запуск IDE

Команда запуска IDE:

```
~/VeriSilicon/VivanteIDE5.5.0/ide/vivanteide5.5.0
```

При запуске сначала выберите директорию рабочей области для сохранения проекта моделирования:

![image-20221208091310996](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091310996.png)

<center>Рисунок 2-20: моделирование IDE</center>

#### 2.7.2 Импорт проекта ovxlib/lenet

В IDE выберите File->Import->General вкладка->Existing Projects into Workspace

![image-20221208091730108](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091730108.png)

<center>Рисунок 2-21: импорт проекта NPU</center>

Затем выберите директорию проекта ovxlib/lenet/, созданную на этапе экспорта модели

![image-20221208091748054](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091748054.png)

<center>Рисунок 2-22: импорт проекта OK</center>

Здесь настоятельно рекомендуется выбрать "Copy projects into workspace". Таким образом проект моделирования будет скопирован в рабочую область IDE, обеспечивая изоляцию от исходной директории экспорта.

Затем нажмите "Finish" для завершения процесса импорта. Импортированная рабочая область выглядит следующим образом:

![image-20221208091811642](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091811642.png)

<center>Рисунок 2-23: моделирование OK</center>

#### 2.7.3 Компиляция проекта

Выполните команду меню Project->Build All для предварительной компиляции проекта моделирования, чтобы убедиться, что нет ошибок (например, ошибочный импорт проекта и т.д.):

![image-20221208091838854](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091838854.png)

<center>Рисунок 2-24: компиляция OK</center>

Компиляция успешна. Создан исполняемый файл lenet. Переходим к следующему шагу.

#### 2.7.4 Конфигурация параметров моделирования

Выполните команду меню Run->Debug Configurations... На вкладке дважды нажмите на OpenVX Application для отображения следующего вывода. По умолчанию кнопки Search Project и Browser будут корректно установлены, как показано ниже. Если нет, пожалуйста, правильно выберите проект и путь приложения согласно результатам компиляции выше.

Наиболее важным параметром в этой вкладке является Program arguments. Для разных сетей в зависимости от количества входов и выходов, введённые параметры отличаются. Для lenet установите следующим образом:

![image-20221208091913430](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091913430.png)

<center>Рисунок 2-25: параметры NPU</center>

Здесь lenet.export.data - это квантизированные веса, они создаются на этапе экспорта модели в проекте ovxlib/lenet, автоматически копируются на этап импорта проекта в IDE, не требуют ручного копирования. А 0.jpg необходимо вручную скопировать в проект IDE:

![image-20221208091937601](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208091937601.png)

<center>Рисунок 2-26: копирование параметров NPU</center>

В качестве входных данных помимо изображений можно использовать входной тензор, созданный на этапе взаимодействия модели. Программа моделирования автоматически запустит разные ветви обработки в зависимости от суффикса файла, гарантируя, что результаты обработки верны.

Нажмите Apply, затем можно начинать формальное моделирование.

#### 2.7.5 Моделирование

Нажмите кнопку Run на панели инструментов, появится диалоговое окно. Нажмите Run для запуска моделирования.

![image-20221208092001120](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092001120.png)

<center>Рисунок 2-27: запуск NPU</center>

Lenet - это небольшая сеть, моделирование завершится быстро. Результат показан ниже. Из вывода консоли можно видеть, что переданный параметр изображение 0.jpg, выходные результаты top5 моделирования показывают, что вероятность вывода взаимодействия 0 составляет 99.0023%, что соответствует ожиданиям.

![image-20221208092059915](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092059915.png)

<center>Рисунок 2-28: результат моделирования NPU</center>

На этом моделирование модели завершается. Переходим к профилированию модели.

### 2.8 Профилирование модели

Профилирование модели может помочь анализировать общую эффективность работы сети, пропускную способность, частоту кадров и производительность каждого слоя. Это инструмент для анализа точности алгоритма, узких мест производительности и других проблем.

Нажмите кнопку Profile рядом с кнопкой Run на панели инструментов для запуска профилирования. Также в этой вкладке нажмите кнопку Profile для продолжения.

![image-20221208092134981](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092134981.png)

<center>Рисунок 2-29: консоль профилирования NPU</center>

Затем нажмите Resume для продолжения:

![image-20221208092154631](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092154631.png)

<center>Рисунок 2-30: ввод профилирования NPU</center>

После завершения профилирования IDE выведет следующее:

![image-20221208092325476](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092325476.png)

<center>Рисунок 2-31: профилирование Lenet NPU</center>

Краткий анализ информации профилирования: слева внизу показаны те же результаты взаимодействия top5, в середине - статистика работы каждого слоя, включая аппаратные блоки обработки каждого слоя, пропускную способность чтения/записи. Для слоёв, вычисляемых PPU, таких как слой softmax, будет также статистика инструкций. Справа внизу показан анализ общей производительности работы сети, включая общую пропускную способность чтения/записи сети, частоту обработки кадров, количество тактов и другую информацию. Для более подробного анализа обратитесь к документации VeriSilicon.

Далее переходим к последнему шагу. Все вышеперечисленные работы были нацелены на развертывание сети на устройстве и её реальный запуск на плате. Начинаем с описания развертывания на устройстве:

### 2.9 Развертывание на устройстве

На этапе моделирования после завершения моделирования в проекте создаются два бинарных файла, необходимые для проверки развертывания: input_0.dat и output0_10_1.dat. Оба файла находятся в двоичном формате.

input_0.dat - это входные данные первого слоя сети, output0_10_1.dat - это выходные данные последнего слоя сети. Поскольку результаты моделирования показывают, что оба набора данных верны, они могут служить эталонными данными для сравнения с результатами работы на устройстве. Если при тех же входных данных выходной тензор, полученный на устройстве, идентичен выходному файлу output_0._10_1.dat в двоичном виде, то развертывание на устройстве выполнено правильно.

Уяснив логику, начинаем с практических операций. Сначала посмотрите эти два файла .dat в проекте моделирования. Файлы с синим фоном слева:

![image-20221208092431537](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092431537.png)

<center>Рисунок 2-32: эталонный тензор</center>

Далее мы используем другой проект, созданный на этапе экспорта модели - проект ovxlib/lenet_nbg_viplite.

#### 2.9.1 Кросс-компиляция проекта ovxlib/lenet_nbg_viplite

Выпущенный нами Tina SDK будет содержать NPU Development SDK. Структура NPU Development SDK показана ниже:

![image-20221208092502665](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092502665.png)

<center>Рисунок 2-33: SDK NPU</center>

Если у вас есть Tina SDK, модуль KMD NPU уже находится в соответствующем коде ядра Linux Tina SDK, в то время как SDK пространства пользователя, то есть представленная NPU runtime library (UMD Driver), находится в директории package/allwinner/ SDK в виде библиотеки.

Скопируйте ovxlib/lenet_nbg_viplite и расположите его рядом с NPU runtime library в одной директории. Напишите файл makefile согласно содержимому ниже (SDK будет включать примерный makefile).

![image-20221208092527322](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092527322.png)

<center>Рисунок 2-34: структура директории проекта</center>

![image-20221208092609567](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092609567.png)

<center>Рисунок 2-35: makefile проекта</center>

В директории проекта директория sdk содержит библиотеку времени выполнения пространства пользователя NPU, то есть драйвер UMD. Содержимое директории lenet_nbg_viplite - это результат проекта lenet_nbg_viplite, созданный на этапе развертывания модели, плюс makefile.

Теперь можно выполнить кросс-компиляцию тестового проекта. В директории lenet_nbg_viplite выполните make clean && make. После завершения выполнения в директории out будет создана тестовая программа lenet, которую можно запустить на устройстве.

![image-20221208092632515](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092632515.png)

<center>Рисунок 2-36: результаты lenet NPU ELF</center>

Кросс-компиляция завершена. Далее подготовьте директорию тестового проекта.

#### 2.9.2 Подготовка директории тестового проекта

Содержимое директории тестового проекта включает файл модели NBG, исполняемую программу lenet, две динамических библиотеки UMD и input_0.dat, созданные на этапе моделирования, всего 5 файлов, как показано ниже:

![image-20221208092713183](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092713183.png)

<center>Рисунок 2-37: тестовая окружение NPU</center>

На данный момент директория тестирования подготовлена. Далее подготовиться платформа проверки на устройстве.

#### 2.9.3 Подготовка окружения проверки на устройстве

Сначала предпосылка запуска NPU на устройстве - наличие узла устройства /dev/vipcore. В противном случае конфигурация SDK неправильна. Обратитесь к нам за помощью.

![image-20221208092735339](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092735339.png)

<center>Рисунок 2-38: устройство NPU</center>

Сохраните созданную ранее директорию тестирования на SD-карту. Используем SD-карту в качестве носителя для проверки. Вставьте SD-карту в платформу на устройстве, затем выполните команду

```
mount -t vfat /dev/mmcblkxxx /mnt/sdcard
```

Смонтируйте её в директорию /mnt/sdcard. Затем перейдите в директорию проверки lenet-test и выполните команду

```
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/mnt/sdcard/lenet-test
```

Убедитесь, что библиотека времени выполнения может быть правильно связана.

Теперь можно начинать формальное тестирование. Выполните команду тестирования

```
./lenet network_binary.nb input_0.dat
```

Результат вывода:

![image-20221208092904086](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092904086.png)

<center>Рисунок 2-39: результат</center>

Обратите внимание на последнюю строку. Вы можете видеть, что в директории тестирования создан новый файл output0_10_1.dat - это результат выходных данных сети.

### 2.10 Проверка

Получили результат взаимодействия на устройстве, сравните его с .dat файлом, созданным при моделировании. При нормальных обстоятельствах они должны быть идентичны в двоичном виде.

![image-20221208092937875](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208092937875.png)

<center>Рисунок 2-40: результат сравнения NPU</center>

Результат Binary Identical, соответствует нашим ожиданиям.

#### 2.10.1 Проверка тензора

На основе описания структуры сети, последний слой сети - это softmax. Слой softmax выводит значения вероятности в виде чисел с плавающей точкой. В конструкции NPU VeriSilicon существуют три типа вычислительных блоков: TP, NNE и PPU. Здесь только PPU поддерживает вычисления с плавающей точкой, поэтому слой softmax должен запускаться на PPU.

Посмотрим информацию выходного слоя в файле NBG, как показано ниже. Видно, что выходные данные - это fp16 (числа с плавающей точкой), без квантизации. На основе проверки beyondcompare выше, мы также можем видеть, что общий выходной тензор составляет 20 байт. Давайте вычислим: сеть классификации lenet распознаёт десять классов. Вероятность каждого класса - это fp16, поэтому в итоге получаем ровно 20 байт. Таким образом мы знаем структуру выходного тензора.

![image-20221208093034585](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208093034585.png)

<center>Рисунок 2-41: информация NB</center>

Зная структуру, мы можем преобразовать созданный выходной тензор в вероятность и вывести результаты. Поскольку 32-битная машина не поддерживает формат FP16, нужно преобразовать его в формат float32, соответствующий стандарту ieee754. Основной код преобразования:

![image-20221208093112338](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208093112338.png)

<center>Рисунок 2-42: преобразование FP16 NPU</center>

Результат вывода:

![image-20221208093127325](http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208093127325.png)

<center>Рисунок 2-43: преобразование в FP32 NPU</center>

Сравнивая с выводом этапа моделирования, полученные результаты TOP5 вероятности полностью совпадают. Это доказывает, что наше развертывание и постобработка правильны.

На этом процесс развертывания и проверки полностью завершён!
